{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOFxJrTZCzOOGw24yeTCJsI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/prrmzz/ElectronicComponent-SqueezeNet/blob/main/ElectronicComponentDetector_SqueezeNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.metrics import roc_auc_score, roc_curve\n",
        "from tensorflow.keras import layers, models\n",
        "from PIL import Image"
      ],
      "metadata": {
        "id": "Ndp6Ij0l2EuZ"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VmcVUiv22Txq",
        "outputId": "c242af2c-dc8d-4360-845e-4a485751a19f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_dir = '/content/drive/My Drive/Electronic_components'\n",
        "component_folders = ['Capacitor', 'Resistor', 'IC', 'Transistor', 'Dataset_Treino']\n",
        "image_size = (224, 224)  # Input size for SqueezeNet\n",
        "batch_size = 32\n",
        "epochs = 10"
      ],
      "metadata": {
        "id": "Ki_gC1uS2aP4"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def is_valid_image(file_path):\n",
        "    try:\n",
        "        img = Image.open(file_path)\n",
        "        img.verify()\n",
        "        return True\n",
        "    except (IOError, SyntaxError):\n",
        "        return False"
      ],
      "metadata": {
        "id": "9x5e9izX2cy5"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_image_paths_and_labels(base_dir, component_folders):\n",
        "    image_paths = []\n",
        "    labels = []\n",
        "    label_mapping = {folder: idx for idx, folder in enumerate(component_folders)}\n",
        "\n",
        "    for folder in component_folders:\n",
        "        folder_path = os.path.join(base_dir, folder)\n",
        "        for file_name in os.listdir(folder_path):\n",
        "            file_path = os.path.join(folder_path, file_name)\n",
        "            if is_valid_image(file_path):\n",
        "                image_paths.append(file_path)\n",
        "                labels.append(label_mapping[folder])\n",
        "            else:\n",
        "                print(f\"Invalid image file skipped: {file_path}\")\n",
        "\n",
        "    return np.array(image_paths), np.array(labels)"
      ],
      "metadata": {
        "id": "gLwzLVnc2h7Q"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_paths, labels = load_image_paths_and_labels(base_dir, component_folders)"
      ],
      "metadata": {
        "id": "YNJDroIi2iwa"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_image(image_path, image_size):\n",
        "\n",
        "    image = tf.io.read_file(image_path)\n",
        "    try:\n",
        "        image = tf.image.decode_image(image, channels=3, expand_animations=False)\n",
        "    except tf.errors.InvalidArgumentError:\n",
        "        return None\n",
        "    image = tf.image.resize(image, image_size)  # Resize the image to the specified size\n",
        "    image = image / 255.0  # Normalize to [0, 1]\n",
        "    return image"
      ],
      "metadata": {
        "id": "RKg0lsOp2mpA"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_dataset(image_paths, labels, image_size, batch_size):\n",
        "    def generator_fn():\n",
        "        for i in range(len(image_paths)):\n",
        "            image = preprocess_image(image_paths[i], image_size)\n",
        "            if image is not None:\n",
        "                yield image, labels[i]\n",
        "\n",
        "    dataset = tf.data.Dataset.from_generator(\n",
        "        generator_fn,\n",
        "        output_signature=(\n",
        "            tf.TensorSpec(shape=image_size + (3,), dtype=tf.float32),  # Image shape\n",
        "            tf.TensorSpec(shape=(), dtype=tf.int32)  # Label shape\n",
        "        )\n",
        "    )\n",
        "    dataset = dataset.shuffle(len(image_paths)).batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
        "    return dataset"
      ],
      "metadata": {
        "id": "3wNModSK2o9A"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = create_dataset(image_paths, labels, image_size, batch_size)"
      ],
      "metadata": {
        "id": "G6BnLIjj04h5"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_size = int(0.7 * len(image_paths))\n",
        "val_size = int(0.15 * len(image_paths))\n",
        "test_size = len(image_paths) - train_size - val_size"
      ],
      "metadata": {
        "id": "6C0XLTGG2tGI"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = dataset.take(train_size)\n",
        "remaining = dataset.skip(train_size)\n",
        "val_dataset = remaining.take(val_size)\n",
        "test_dataset = remaining.skip(val_size)"
      ],
      "metadata": {
        "id": "vO0eB9SS2u7y"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_faster_squeezenet(input_shape=(128, 128, 3), num_classes=5):\n",
        "    inputs = layers.Input(shape=input_shape)\n",
        "\n",
        "    # Initial Convolution with BatchNorm\n",
        "    x = layers.Conv2D(32, (3, 3), strides=(2, 2), padding='same')(inputs)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Activation('relu')(x)\n",
        "    x = layers.MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding='same')(x)\n",
        "\n",
        "    # Fire Module with Dense and Residual Connections\n",
        "    def fire_module(x, squeeze, expand):\n",
        "\n",
        "        input_tensor = x\n",
        "\n",
        "        # Squeeze layer\n",
        "        squeeze_layer = layers.Conv2D(squeeze, (1, 1), padding='valid')(x)\n",
        "        squeeze_layer = layers.BatchNormalization()(squeeze_layer)\n",
        "        squeeze_layer = layers.Activation('relu')(squeeze_layer)\n",
        "\n",
        "        # Expand layer\n",
        "        expand_1x1 = layers.Conv2D(expand, (1, 1), padding='valid')(squeeze_layer)\n",
        "        expand_1x1 = layers.BatchNormalization()(expand_1x1)\n",
        "        expand_1x1 = layers.Activation('relu')(expand_1x1)\n",
        "\n",
        "        expand_3x3 = layers.Conv2D(expand, (3, 3), padding='same')(squeeze_layer)\n",
        "        expand_3x3 = layers.BatchNormalization()(expand_3x3)\n",
        "        expand_3x3 = layers.Activation('relu')(expand_3x3)\n",
        "\n",
        "        # Concatenate outputs\n",
        "        x = layers.Concatenate()([expand_1x1, expand_3x3])\n",
        "\n",
        "        # Skip connection (like ResNet)\n",
        "        if x.shape[-1] != input_tensor.shape[-1]:\n",
        "            input_tensor = layers.Conv2D(x.shape[-1], (1, 1), padding='same')(input_tensor)\n",
        "            x = layers.add([x, input_tensor])\n",
        "\n",
        "        return x\n",
        "\n",
        "    # Block 1\n",
        "    x = fire_module(x, squeeze=16, expand=32)\n",
        "    x = fire_module(x, squeeze=16, expand=32)\n",
        "    x = layers.MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding='same')(x)\n",
        "\n",
        "    # Block 2\n",
        "    x = fire_module(x, squeeze=32, expand=64)\n",
        "    x = fire_module(x, squeeze=32, expand=64)\n",
        "    x = layers.MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding='same')(x)\n",
        "\n",
        "    # Block 3\n",
        "    x = fire_module(x, squeeze=64, expand=128)\n",
        "    x = layers.Dropout(0.5)(x)\n",
        "\n",
        "    # Final Layers\n",
        "    x = layers.Conv2D(num_classes, (1, 1), padding='valid')(x)\n",
        "    x = layers.GlobalAveragePooling2D()(x)\n",
        "    outputs = layers.Activation('softmax')(x)\n",
        "\n",
        "    return models.Model(inputs, outputs)"
      ],
      "metadata": {
        "id": "A3Z_FAkm2v5w"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = build_faster_squeezenet(input_shape=image_size + (3,), num_classes=len(component_folders))\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "gW_ECj_e25XB"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(train_dataset, validation_data=val_dataset, epochs=epochs)"
      ],
      "metadata": {
        "id": "ms90-Vuby30q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d047727-d1e8-4125-d854-1b6fc19eddb8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_accuracy = model.evaluate(test_dataset)\n",
        "print(f\"Test Accuracy: {test_accuracy:.2f}\")"
      ],
      "metadata": {
        "id": "Kt0cMbhAy6rK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_true = np.concatenate([y for x, y in test_dataset], axis=0)\n",
        "y_pred = model.predict(test_dataset)\n",
        "y_pred = np.argmax(y_pred, axis=1)"
      ],
      "metadata": {
        "id": "rFhf9h1nrI3H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(component_folders)):\n",
        "    fpr, tpr, _ = roc_curve(y_true == i, y_pred == i)\n",
        "    auc = roc_auc_score(y_true == i, y_pred == i)\n",
        "    print(f\"Class: {component_folders[i]}, AUC: {auc:.4f}, TPR: {tpr[1]:.4f}, FPR: {fpr[1]:.4f}\")"
      ],
      "metadata": {
        "id": "AHBCo9GhrLuY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}